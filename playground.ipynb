{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Global Optimization in Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read SVHN Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "x = loadmat('svhn_data/train_32x32.mat')\n",
    "y = loadmat('svhn_data/test_32x32.mat')\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.layers as layers\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import TensorBoard\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = x['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.swapaxes(np.swapaxes(np.swapaxes(x['X'],2,3), 1,2), 0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = y['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = np.swapaxes(np.swapaxes(np.swapaxes(y['X'],2,3), 1,2), 0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(position):\n",
    "    image = train_features[position, :, : ,:].squeeze()\n",
    "    plt.title('Example %d. Label: %d' % (position, train_labels[position]))\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_image(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>5727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>5595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>5045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>4659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>4948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  Count\n",
       "0      1  13861\n",
       "1      2  10585\n",
       "2      3   8497\n",
       "3      4   7458\n",
       "4      5   6882\n",
       "5      6   5727\n",
       "6      7   5595\n",
       "7      8   5045\n",
       "8      9   4659\n",
       "9     10   4948"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_count = np.unique(train_labels, return_counts=True)\n",
    "dataframe_train_labels = pd.DataFrame({'Label':train_labels_count[0], 'Count':train_labels_count[1]})\n",
    "dataframe_train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = {}\n",
    "train_features, validation_features, train_labels, validation_labels = train_test_split(train_features, train_labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58605, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training images: 58605\n",
      "# of validation images: 14652\n"
     ]
    }
   ],
   "source": [
    "print('# of training images:', train_features.shape[0])\n",
    "print('# of validation images:', validation_features.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create sample model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters to experiment with\n",
    "\n",
    "Implement Bayesian Global Optimization to arrive at optimal hyper parameter values for:\n",
    "1. Starting Learning Rate $\\eta_0$\n",
    "2. Learning Rate Decay $\\delta$ where learning-rate $\\eta = \\frac{\\eta_0}{(1+\\delta*t)}$ \n",
    "3. Mini-batch size: $B$\n",
    "4. Dropout parameter $p_1$ for first fully connected layer\n",
    "5. Dropout parameter $p_2$ for second fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STARTING_LEARNING_RATE = 0.001\n",
    "# DECAY = 0.0000001\n",
    "# BATCH_SIZE = 256\n",
    "# DROPOUT_P1 = 0.001\n",
    "# DROPOUT_P2 = 0.001\n",
    "#EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STARTING_LEARNING_RATE = [0.001,0.01,0.05,0.1]\n",
    "# DECAY = [0.0000001,0.000001,0.0001]\n",
    "# # BATCH_SIZE = [32, 64, 128] #256,512,1024]\n",
    "# BATCH_SIZE = [256,512,1024]\n",
    "# DROPOUT_P1 = [0.1,0.25,0.5]\n",
    "# DROPOUT_P2 = [0.1,0.25,0.5]\n",
    "# EPOCHS = 1\n",
    "\n",
    "STARTING_LEARNING_RATE = [0.001,0.01]\n",
    "DECAY = [0.0000001,0.00001]\n",
    "# BATCH_SIZE = [32, 64, 128] #256,512,1024]\n",
    "BATCH_SIZE = [256,512]\n",
    "DROPOUT_P1 = [0.1, 0.4]\n",
    "DROPOUT_P2 = [0.1, 0.4]\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_features, to_categorical(train_labels)[:,1:]\n",
    "# X_train = train_features\n",
    "X_validation, y_validation = validation_features, to_categorical(validation_labels)[:,1:]\n",
    "\n",
    "#Comment when running Grid Search\n",
    "#train_generator = ImageDataGenerator().flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
    "#validation_generator = ImageDataGenerator().flow(X_validation, y_validation, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 256 1e-07 0.1 0.1\n",
      "WARNING:tensorflow:From C:\\Users\\Ankush\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Ankush\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Ankush\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "228/228 [==============================] - 10s 45ms/step - loss: 14.8403 - acc: 0.0792 - val_loss: 14.9108 - val_acc: 0.0749\n",
      "17696/26032 [===================>..........] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "############# LENET #############\n",
    "# model = keras.Sequential()\n",
    "\n",
    "# model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(32,32,3)))\n",
    "# model.add(layers.AveragePooling2D())\n",
    "\n",
    "# model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "# model.add(layers.AveragePooling2D())\n",
    "\n",
    "# model.add(layers.Flatten())\n",
    "\n",
    "# model.add(layers.Dense(units=120, activation='relu'))\n",
    "\n",
    "# model.add(layers.Dense(units=84, activation='relu'))\n",
    "\n",
    "# model.add(layers.Dense(units=10, activation = 'softmax'))\n",
    "# #, kernel_initializer=\"glorot_uniform\", bias_initializer=\"zeros\")\n",
    "\n",
    "\n",
    "############# Proposed Model #############\n",
    "# model = keras.Sequential()\n",
    "# model.add(layers.Conv2D(filters=32, kernel_size=(5, 5), activation='relu', input_shape=(32,32,3), strides=1, padding='same', kernel_initializer=\"he_uniform\", bias_initializer=\"zeros\"))\n",
    "# #model.add(layers.AveragePooling2D())\n",
    "\n",
    "# model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', strides=1, padding='same', kernel_initializer=\"he_uniform\", bias_initializer=\"zeros\"))\n",
    "# #model.add(layers.AveragePooling2D())\n",
    "# model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', strides=1, padding='same', kernel_initializer=\"he_uniform\", bias_initializer=\"zeros\"))\n",
    "\n",
    "# model.add(layers.Flatten())\n",
    "\n",
    "# model.add(layers.Dense(units=1024, activation='relu', kernel_initializer=\"glorot_uniform\", bias_initializer=\"zeros\"))\n",
    "# model.add(layers.Dropout(rate=DROPOUT_P1, seed=1))\n",
    "# model.add(layers.Dense(units=1024, activation='relu', kernel_initializer=\"glorot_uniform\", bias_initializer=\"zeros\"))\n",
    "# model.add(layers.Dropout(rate=DROPOUT_P2, seed=1))\n",
    "# model.add(layers.Dense(units=10, activation = 'softmax'))\n",
    "\n",
    "\n",
    "############# Grid Search #############\n",
    "result=[]\n",
    "for lr in STARTING_LEARNING_RATE:\n",
    "    for b in BATCH_SIZE:\n",
    "        for dec in DECAY:\n",
    "            for d1 in DROPOUT_P1:\n",
    "                for d2 in DROPOUT_P2:\n",
    "                    \n",
    "                    print(lr, b, dec, d1, d2)\n",
    "                    \n",
    "                    train_generator = ImageDataGenerator().flow(X_train, y_train, batch_size=b)\n",
    "                    validation_generator = ImageDataGenerator().flow(X_validation, y_validation, batch_size=b)\n",
    "\n",
    "                    model = keras.Sequential()\n",
    "                    model.add(layers.Conv2D(filters=32, kernel_size=(5, 5), activation='relu', input_shape=(32,32,3), strides=1, padding='same', kernel_initializer=\"he_uniform\", bias_initializer=\"zeros\"))\n",
    "                    model.add(layers.AveragePooling2D())\n",
    "\n",
    "                    model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', strides=1, padding='same', kernel_initializer=\"he_uniform\", bias_initializer=\"zeros\"))\n",
    "                    model.add(layers.AveragePooling2D())\n",
    "                    model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', strides=1, padding='same', kernel_initializer=\"he_uniform\", bias_initializer=\"zeros\"))\n",
    "\n",
    "                    model.add(layers.Flatten())\n",
    "\n",
    "                    model.add(layers.Dense(units=1024, activation='relu', kernel_initializer=\"glorot_uniform\", bias_initializer=\"zeros\"))\n",
    "                    model.add(layers.Dropout(rate=d1, seed=10))\n",
    "                    model.add(layers.Dense(units=1024, activation='relu', kernel_initializer=\"glorot_uniform\", bias_initializer=\"zeros\"))\n",
    "                    model.add(layers.Dropout(rate=d2, seed=10))\n",
    "                    model.add(layers.Dense(units=10, activation = 'softmax'))\n",
    "                    \n",
    "                    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(lr=lr,decay=dec), metrics=['accuracy'])\n",
    "                    \n",
    "#                     print('# of training images:', train_features.shape[0])\n",
    "#                     print('# of validation images:', validation_features.shape[0])\n",
    "\n",
    "                    steps_per_epoch = X_train.shape[0]//b\n",
    "                    validation_steps = X_validation.shape[0]//b\n",
    "\n",
    "                    tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "                    model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, \n",
    "                                        validation_data=validation_generator, validation_steps=validation_steps, \n",
    "                                        shuffle=False, callbacks=[tensorboard])\n",
    "                \n",
    "                    score = model.evaluate(test_features, to_categorical(test_labels)[:,1:])\n",
    "                    result.append(((lr,b,dec,d1,d2),score))\n",
    "                    print('Test loss: {} Accuracy: {}'.format(score[0], score[1]))\n",
    "                    del train_generator, validation_generator, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0.001, 256, 1e-07, 0.1, 0.1), [12.960974684506013, 0.1958743085433313]),\n",
       " ((0.001, 256, 1e-07, 0.4, 0.4), [12.960974684506013, 0.1958743085433313]),\n",
       " ((0.001, 256, 1e-05, 0.1, 0.1), [12.960974684506013, 0.1958743085433313]),\n",
       " ((0.001, 256, 1e-05, 0.1, 0.4), [12.960974684506013, 0.1958743085433313]),\n",
       " ((0.001, 512, 1e-07, 0.4, 0.1), [12.960974684506013, 0.1958743085433313]),\n",
       " ((0.001, 512, 1e-07, 0.1, 0.1), [13.549181133380461, 0.15938076213890595]),\n",
       " ((0.001, 512, 1e-05, 0.4, 0.1), [13.549181133380461, 0.15938076213890595]),\n",
       " ((0.001, 256, 1e-05, 0.4, 0.1), [14.333662611029965, 0.1107098955132145]),\n",
       " ((0.001, 512, 1e-07, 0.4, 0.4), [14.333662611029965, 0.1107098955132145]),\n",
       " ((0.001, 256, 1e-07, 0.4, 0.1), [14.55594267842223, 0.09691917639827904]),\n",
       " ((0.001, 256, 1e-05, 0.4, 0.4), [14.55594267842223, 0.09691917639827904]),\n",
       " ((0.001, 256, 1e-07, 0.1, 0.4), [14.89400650814551, 0.07594499078057775]),\n",
       " ((0.001, 512, 1e-05, 0.1, 0.1), [14.89400650814551, 0.07594499078057775]),\n",
       " ((0.001, 512, 1e-05, 0.4, 0.4), [14.89400650814551, 0.07594499078057775]),\n",
       " ((0.01, 256, 1e-07, 0.1, 0.1), [15.09028173328252, 0.06376767055931162]),\n",
       " ((0.01, 256, 1e-07, 0.1, 0.4), [15.09028173328252, 0.06376767055931162]),\n",
       " ((0.001, 512, 1e-07, 0.1, 0.4), [15.130527435377763, 0.06127074370006146]),\n",
       " ((0.001, 512, 1e-05, 0.1, 0.4), [15.130527435377763, 0.06127074370006146])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#result\n",
    "sorted(result, key = lambda x: x[1][1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_88 (Conv2D)           (None, 32, 32, 32)        2432      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_59 (Averag (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_89 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_60 (Averag (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "flatten_30 (Flatten)         (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 1024)              8389632   \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 9,544,266\n",
      "Trainable params: 9,544,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "#result[0][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comment for Grid Search\n",
    "#model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(lr=STARTING_LEARNING_RATE,decay=DECAY), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# of training images:', train_features.shape[0])\n",
    "print('# of validation images:', validation_features.shape[0])\n",
    "\n",
    "steps_per_epoch = X_train.shape[0]//BATCH_SIZE\n",
    "validation_steps = X_validation.shape[0]//BATCH_SIZE\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=EPOCHS,\n",
    "                    validation_data=validation_generator, validation_steps=validation_steps, \n",
    "                    shuffle=False, callbacks=[tensorboard])\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_features, to_categorical(test_labels)[:,1:])\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "larger batch size, watch your weight initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "equations, figures all labeled and cited. References discussed. Put a few equations, Glorot et.al [1], discuss a couple of papers in related work, section headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ankush\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Ankush\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Ankush\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "228/228 [==============================] - 61s 266ms/step - loss: 15.0257 - acc: 0.0678 - val_loss: 15.0367 - val_acc: 0.0671\n",
      "Epoch 2/20\n",
      "228/228 [==============================] - 59s 259ms/step - loss: 15.0230 - acc: 0.0679 - val_loss: 15.0444 - val_acc: 0.0666\n",
      "Epoch 3/20\n",
      "228/228 [==============================] - 59s 258ms/step - loss: 15.0303 - acc: 0.0675 - val_loss: 15.0365 - val_acc: 0.0671\n",
      "Epoch 4/20\n",
      "228/228 [==============================] - 59s 259ms/step - loss: 15.0260 - acc: 0.0678 - val_loss: 15.0388 - val_acc: 0.0670\n",
      "Epoch 5/20\n",
      "228/228 [==============================] - 59s 259ms/step - loss: 15.0309 - acc: 0.0675 - val_loss: 15.0410 - val_acc: 0.0668\n",
      "Epoch 6/20\n",
      "228/228 [==============================] - 60s 261ms/step - loss: 15.0198 - acc: 0.0681 - val_loss: 15.0466 - val_acc: 0.0665\n",
      "Epoch 7/20\n",
      "228/228 [==============================] - 59s 260ms/step - loss: 15.0296 - acc: 0.0675 - val_loss: 15.0444 - val_acc: 0.0666\n",
      "Epoch 8/20\n",
      "228/228 [==============================] - 59s 260ms/step - loss: 15.0265 - acc: 0.0677 - val_loss: 15.0052 - val_acc: 0.0690\n",
      "Epoch 9/20\n",
      "228/228 [==============================] - 59s 261ms/step - loss: 15.0300 - acc: 0.0675 - val_loss: 15.0645 - val_acc: 0.0654\n",
      "Epoch 10/20\n",
      "228/228 [==============================] - 59s 259ms/step - loss: 15.0253 - acc: 0.0678 - val_loss: 15.0388 - val_acc: 0.0670\n",
      "Epoch 11/20\n",
      "228/228 [==============================] - 60s 262ms/step - loss: 15.0277 - acc: 0.0676 - val_loss: 15.0253 - val_acc: 0.0678\n",
      "Epoch 12/20\n",
      "228/228 [==============================] - 60s 261ms/step - loss: 15.0236 - acc: 0.0679 - val_loss: 15.0746 - val_acc: 0.0647\n",
      "Epoch 13/20\n",
      "228/228 [==============================] - 59s 260ms/step - loss: 15.0283 - acc: 0.0676 - val_loss: 15.0141 - val_acc: 0.0685\n",
      "Epoch 14/20\n",
      "228/228 [==============================] - 60s 262ms/step - loss: 15.0260 - acc: 0.0678 - val_loss: 15.0477 - val_acc: 0.0664\n",
      "Epoch 15/20\n",
      "228/228 [==============================] - 59s 260ms/step - loss: 15.0245 - acc: 0.0679 - val_loss: 15.0332 - val_acc: 0.0673\n",
      "Epoch 16/20\n",
      "228/228 [==============================] - 59s 260ms/step - loss: 15.0345 - acc: 0.0672 - val_loss: 15.0556 - val_acc: 0.0659\n",
      "Epoch 17/20\n",
      "228/228 [==============================] - 60s 264ms/step - loss: 15.0199 - acc: 0.0681 - val_loss: 15.0041 - val_acc: 0.0691\n",
      "Epoch 18/20\n",
      "228/228 [==============================] - 60s 261ms/step - loss: 15.0251 - acc: 0.0678 - val_loss: 15.0623 - val_acc: 0.0655\n",
      "Epoch 19/20\n",
      "228/228 [==============================] - 59s 260ms/step - loss: 15.0327 - acc: 0.0673 - val_loss: 15.0265 - val_acc: 0.0677\n",
      "Epoch 20/20\n",
      "228/228 [==============================] - 59s 259ms/step - loss: 15.0335 - acc: 0.0673 - val_loss: 15.0455 - val_acc: 0.0665\n",
      "26032/26032 [==============================] - 8s 290us/step\n",
      "Test loss: 15.038271879959341 Accuracy: 0.06699446834665028\n"
     ]
    }
   ],
   "source": [
    "b = 256\n",
    "\n",
    "train_generator = ImageDataGenerator().flow(X_train, y_train, batch_size=b)\n",
    "validation_generator = ImageDataGenerator().flow(X_validation, y_validation, batch_size=b)\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Conv2D(filters=32, kernel_size=(5, 5), activation='relu', input_shape=(32,32,3), strides=1, padding='same', kernel_initializer=\"he_uniform\", bias_initializer=\"zeros\"))\n",
    "#model.add(layers.AveragePooling2D())\n",
    "\n",
    "model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', strides=1, padding='same', kernel_initializer=\"he_uniform\", bias_initializer=\"zeros\"))\n",
    "#model.add(layers.AveragePooling2D())\n",
    "model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', strides=1, padding='same', kernel_initializer=\"he_uniform\", bias_initializer=\"zeros\"))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(units=1024, activation='relu', kernel_initializer=\"glorot_uniform\", bias_initializer=\"zeros\"))\n",
    "model.add(layers.Dropout(rate=0.1, seed=10))\n",
    "model.add(layers.Dense(units=1024, activation='relu', kernel_initializer=\"glorot_uniform\", bias_initializer=\"zeros\"))\n",
    "model.add(layers.Dropout(rate=0.1, seed=10))\n",
    "model.add(layers.Dense(units=10, activation = 'softmax'))\n",
    "            \n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(lr=0.001,decay=0.0000001), metrics=['accuracy'])\n",
    "steps_per_epoch = X_train.shape[0]//b\n",
    "validation_steps = X_validation.shape[0]//b\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, \n",
    "                    validation_data=validation_generator, validation_steps=validation_steps, \n",
    "                    shuffle=False, callbacks=[tensorboard])\n",
    "\n",
    "score = model.evaluate(test_features, to_categorical(test_labels)[:,1:])\n",
    "print('Test loss: {} Accuracy: {}'.format(score[0], score[1]))\n",
    "# ############# Grid Search #############\n",
    "# result=[]\n",
    "# for lr in STARTING_LEARNING_RATE:\n",
    "#     for b in BATCH_SIZE:\n",
    "#         for dec in DECAY:\n",
    "                    \n",
    "#             print(lr, b, dec)\n",
    "\n",
    "#             train_generator = ImageDataGenerator().flow(X_train, y_train, batch_size=b)\n",
    "#             validation_generator = ImageDataGenerator().flow(X_validation, y_validation, batch_size=b)\n",
    "\n",
    "#             model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(lr=lr,decay=dec), metrics=['accuracy'])\n",
    "\n",
    "# #                     print('# of training images:', train_features.shape[0])\n",
    "# #                     print('# of validation images:', validation_features.shape[0])\n",
    "\n",
    "#             steps_per_epoch = X_train.shape[0]//b\n",
    "#             validation_steps = X_validation.shape[0]//b\n",
    "\n",
    "#             tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "#             model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, \n",
    "#                                 validation_data=validation_generator, validation_steps=validation_steps, \n",
    "#                                 shuffle=False, callbacks=[tensorboard])\n",
    "\n",
    "#             score = model.evaluate(test_features, to_categorical(test_labels)[:,1:])\n",
    "#             result.append(((lr,b,dec),score))\n",
    "#             print('Test loss: {} Accuracy: {}'.format(score[0], score[1]))\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
