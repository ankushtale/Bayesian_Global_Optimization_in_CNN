{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FSL_Project_Hyper_parameter_optimization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwWjbueLamJv",
        "colab_type": "text"
      },
      "source": [
        "#Importing relevant libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YALrZKl7bQjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Requirements\n",
        "#pip install bayesian-optimization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2dlVeU-gS5j",
        "colab_type": "code",
        "outputId": "b76a34d4-b674-45ba-bfbc-a741cd169328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gzip\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "from scipy.interpolate import BSpline as spline\n",
        "from time import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "import keras.layers as layers\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Dropout, BatchNormalization, MaxPooling2D, Flatten, Activation, AveragePooling2D\n",
        "from tensorflow.python.keras.optimizer_v2 import rmsprop\n",
        "from bayes_opt import BayesianOptimization\n",
        "from bayes_opt import BayesianOptimization\n",
        "from bayes_opt import UtilityFunction\n",
        "from functools import partial\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_XnfR8qaxQR",
        "colab_type": "text"
      },
      "source": [
        "# Reading SVHN Cropped image data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BevAo7LwA8nv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.io import loadmat\n",
        "x = loadmat('train_32x32.mat')\n",
        "y = loadmat('test_32x32.mat')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSzHSA_Ta59j",
        "colab_type": "text"
      },
      "source": [
        "# Subsampling and splitting into training and testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7MaFzJmBcnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_CLASSES = 10\n",
        "input_shape = (32,32,3)\n",
        "\n",
        "train_features = np.swapaxes(np.swapaxes(np.swapaxes(x['X'],2,3), 1,2), 0,1)\n",
        "train_labels = x['y']\n",
        "test_features = np.swapaxes(np.swapaxes(np.swapaxes(y['X'],2,3), 1,2), 0,1)\n",
        "test_labels = y['y']\n",
        "\n",
        "train_features, validation_features, train_labels, validation_labels = train_test_split(train_features, train_labels, test_size=0.2, random_state=0)\n",
        "train_features, validation_features, train_labels, validation_labels = train_test_split(validation_features, validation_labels, test_size=0.2, random_state=0)\n",
        "train_labels = train_labels.reshape((train_labels.shape[0],))\n",
        "validation_labels = validation_labels.reshape((validation_labels.shape[0],))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1dBqtYzbC1_",
        "colab_type": "text"
      },
      "source": [
        "# Converting data into relevant data format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNcL-CJzHRnH",
        "colab_type": "code",
        "outputId": "027a117d-dd79-4380-e229-4fb10df94f45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "use_bfloat16=False\n",
        "img_rows, img_cols = 32, 32\n",
        "\n",
        "cast_dtype = tf.bfloat16 if use_bfloat16 else tf.float32\n",
        "\n",
        "x_test = validation_features\n",
        "y_test = validation_labels\n",
        "\n",
        "x_train = train_features\n",
        "y_train = train_labels\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_train = y_train[:,1:]\n",
        "y_test = tf.keras.utils.to_categorical(y_test)\n",
        "y_test = y_test[:,1:]\n",
        "\n",
        "# train dataset\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_ds = train_ds.repeat()\n",
        "\n",
        "# train_ds = train_ds.shuffle(seed=10)\n",
        "train_ds = train_ds.map(lambda x, y: (tf.cast(x, cast_dtype), y))\n",
        "train_ds = train_ds.batch(64, drop_remainder=True)\n",
        "\n",
        "# eval dataset\n",
        "eval_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "eval_ds = eval_ds.repeat()\n",
        "\n",
        "# eval_ds = eval_ds.shuffle(seed=10,buffer_size=10)\n",
        "eval_ds = eval_ds.map(lambda x, y: (tf.cast(x, cast_dtype), y))\n",
        "eval_ds = eval_ds.batch(64, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11721, 32, 32, 3) (11721,)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90HnLuukdKDL",
        "colab_type": "text"
      },
      "source": [
        "# Function which holds the given CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Uz2gZ2wOvHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(input_shape, dropout1_rate=0.25, dropout2_rate=0.5):\n",
        "    \"\"\"Builds a Sequential CNN model to recognize SVHN.\n",
        "    Args:\n",
        "      input_shape: Depends on the image data format. For SVHN, it is (32,32,3).\n",
        "      dropout1_rate: float between 0 and 1. Fraction of the input units to drop for `dense1` layer.\n",
        "      dropout2_rate: float between 0 and 1. Fraction of the input units to drop for `dense2` layer.\n",
        "    Returns:\n",
        "      a Keras model\n",
        "    \"\"\"\n",
        "    # Reset the tensorflow backend session.\n",
        "    # tf.keras.backend.clear_session()\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=(5, 5),\n",
        "                     activation='relu',\n",
        "                     input_shape=input_shape,\n",
        "                     name=\"conv2d_1\", strides=1, padding='valid', kernel_initializer=\"he_uniform\", bias_initializer=\"zeros\"))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3, 3), \n",
        "                     activation='relu', name=\"conv2d_2\", \n",
        "                     strides=1, padding='valid', kernel_initializer=\"he_uniform\", bias_initializer=\"zeros\"))\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3, 3), \n",
        "                     activation='relu', name=\"conv2d_3\", \n",
        "                     strides=1, padding='same', kernel_initializer=\"he_uniform\", bias_initializer=\"zeros\")) \n",
        "    model.add(Flatten(name=\"flatten\"))\n",
        "    model.add(Dense(units=1024, activation='relu', name=\"dense_1\", kernel_initializer=\"glorot_uniform\", bias_initializer=\"zeros\"))\n",
        "    model.add(Dropout(dropout1_rate, name=\"dropout_1\"))\n",
        "    model.add(Dense(units=1024, activation='relu', name=\"dense_2\", kernel_initializer=\"glorot_uniform\", bias_initializer=\"zeros\"))\n",
        "    model.add(Dropout(dropout2_rate, name=\"dropout_2\"))\n",
        "    model.add(Dense(NUM_CLASSES, activation='softmax', name=\"dense_3\"))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0SfX-e1dVbJ",
        "colab_type": "text"
      },
      "source": [
        "# Function which returns the accuracy by running the previous function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuN3o0OigaMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_with(input_shape, verbose, dropout1_rate, dropout2_rate, lr, batch_size, decay_rate):\n",
        "    # Create the model using a specified hyperparameters.\n",
        "    model = get_model(input_shape, dropout1_rate, dropout2_rate)\n",
        "\n",
        "    # Train the model for a specified number of epochs.\n",
        "    optimizer = tf.keras.optimizers.Adam(lr=lr,decay=decay_rate)\n",
        "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Train the model with the train dataset.\n",
        "    model.fit(x=train_ds, epochs=1, steps_per_epoch=batch_size, verbose=verbose)\n",
        "\n",
        "    # Evaluate the model with the eval dataset.\n",
        "    score = model.evaluate(eval_ds, steps=10, verbose=0)\n",
        "    print('Test loss:', score[0])\n",
        "    print('Test accuracy:', score[1])\n",
        "\n",
        "    # To Return the loss, return score[0]\n",
        "    # To Return the accuracy, return score[1].\n",
        "    return score[1]\n",
        "\n",
        "verbose = 0\n",
        "fit_with_partial = partial(fit_with, input_shape, verbose)\n",
        "\n",
        "# To check whether the function is working or not\n",
        "# fit_with_partial(dropout1_rate=0.25, dropout2_rate=0.5, lr=0.001, batch_size=512, decay_rate=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6xWTSN3dnsf",
        "colab_type": "text"
      },
      "source": [
        "# Creating object which maximizes the target function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBW3fChggeSI",
        "colab_type": "code",
        "outputId": "c2bb2f36-9836-4d13-f572-089dfb659d7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Bounded region of parameter space\n",
        "pbounds = {'dropout1_rate': (0, 0.5), 'dropout2_rate': (0, 0.5), 'lr': (1e-6, 1e-1), 'batch_size': (32,512), 'decay_rate': (0, 0.5)}\n",
        "\n",
        "# Function which maximizes the black box function\n",
        "# verbose = 0 is silent\n",
        "# verbose = 1 prints only when a maximum is observed\n",
        "optimizer = BayesianOptimization(\n",
        "    f=fit_with_partial,\n",
        "    pbounds=pbounds,\n",
        "    verbose=2, \n",
        "    random_state=1,\n",
        ")\n",
        "\n",
        "# Prints the maximum value achieved\n",
        "# print(optimizer.max)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 279 µs, sys: 943 µs, total: 1.22 ms\n",
            "Wall time: 1.03 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ddu8449bhgbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reading the csv file which contains the values of the hyper parameter and its corresponding accuracy value \n",
        "df = pd.read_csv(\"lr.csv\")\n",
        "# df = pd.read_csv(\"decayrate.csv\")\n",
        "# df = pd.read_csv(\"dropout.csv\")\n",
        "# df = pd.read_csv(\"DROPOUT_P1.csv\")\n",
        "\n",
        "#LR\n",
        "df['params'] = df.params.replace({\"DROPOUT_P1=0.2, DROPOUT_P2=0.2, batch_size=128, decay=1e-06, lr=\":\"\"},regex=True)\n",
        "#DECAY\n",
        "# df['params'] = df.params.replace({\"DROPOUT_P1=0.2, DROPOUT_P2=0.2, batch_size=128, decay=\":\"\", \", lr=0.02\":\"\"},regex=True)\n",
        "#DROPOUT 2\n",
        "# df['params'] = df.params.replace({\"DROPOUT_P1=0.2, DROPOUT_P2=\":\"\", \", batch_size=128, decay=1e-06, lr=0.02\":\"\"},regex=True)\n",
        "\n",
        "x = np.array(df['params'])\n",
        "y = np.array(df['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bBg3LYBd2G1",
        "colab_type": "text"
      },
      "source": [
        "# GP Regression and Plotting the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaUzGDg5X8KW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function which fits a Gaussian on our training data, and returns its Mean and Variance \n",
        "def posterior(optimizer, x_obs, y_obs, x):\n",
        "    optimizer._gp.fit(x_obs, y_obs)\n",
        "    mu, sigma = optimizer._gp.predict(x, return_std=True)\n",
        "    return mu, sigma\n",
        "\n",
        "# Function which plots the target function, the mean and confidence, and the sampled points\n",
        "def plot_gp(optimizer, x, y):\n",
        "    fig = plt.figure(figsize=(16, 10))\n",
        "    steps = len(optimizer.space)\n",
        "    fig.suptitle(\n",
        "        'Gaussian Process and Utility Function After {} Steps'.format(steps),\n",
        "        fontdict={'size':30}\n",
        "    )\n",
        "    \n",
        "    gs = gridspec.GridSpec(2, 1, height_ratios=[3, 1]) \n",
        "    acq = plt.subplot(gs[1])\n",
        "    plt.subplots_adjust(hspace=1)\n",
        "    \n",
        "    x_obs = np.array([[res[\"params\"][\"decay_rate\"]] for res in optimizer.res])\n",
        "    # x_obs = np.array([[res[\"params\"][\"dropout_rate1\"]] for res in optimizer.res])\n",
        "    # x_obs = np.array([[res[\"params\"][\"dropout_rate2\"]] for res in optimizer.res])\n",
        "    # x_obs = np.array([[res[\"params\"][\"lr\"]] for res in optimizer.res])\n",
        "\n",
        "    y_obs = np.array([res[\"target\"] for res in optimizer.res])\n",
        "    \n",
        "    # Fitting the gaussian, and sampling from it\n",
        "    mu, sigma = posterior(optimizer, x_obs, y_obs, x.reshape(x.shape[0],1))\n",
        "\n",
        "    ax=fig.add_subplot(gs[0], label=\"1\")\n",
        "    ax2=fig.add_subplot(gs[0], label=\"2\", frame_on=False)\n",
        "    ax3=fig.add_subplot(gs[0], label=\"3\", frame_on=False)\n",
        "\n",
        "    ax.plot(x, y, linewidth=3, label='Target')\n",
        "    ax2.plot(x, mu, '--', color='k', label='Prediction')\n",
        "    ax2.set_xticklabels([])\n",
        "    ax2.set_yticklabels([])\n",
        "    ax2.fill(np.concatenate([x, x[::-1]]), \n",
        "              np.concatenate([mu - sigma, (mu + sigma)[::-1]]),\n",
        "        alpha=.6, fc='c', ec='None', label='95% confidence interval')\n",
        "    ax2.set_xlim((0, 50))\n",
        "    ax2.set_ylim((None, None))\n",
        "    ax2.set_ylabel('f(x)', fontdict={'size':20})\n",
        "    ax3.plot(x_obs, y_obs, 'D', markersize=8, label=u'Observations', color='r')\n",
        "    ax3.set_xticklabels([])\n",
        "    ax3.set_yticklabels([])\n",
        "    plt.sca(ax)\n",
        "    plt.xticks(rotation='vertical')\n",
        "        \n",
        "    # Calculates the utility or acquisition function, and the next best guess \n",
        "    utility_function = UtilityFunction(kind=\"ucb\", kappa=5, xi=0)\n",
        "    utility = utility_function.utility(x.reshape(x.shape[0],1), optimizer._gp, 0)\n",
        "    acq.plot(x, utility, label='Utility Function', color='purple')\n",
        "    acq.plot(x[np.argmax(utility)], np.max(utility), '*', markersize=15, \n",
        "              label=u'Next Best Guess', markerfacecolor='gold', markeredgecolor='k', markeredgewidth=1)\n",
        "    acq.set_xlim((0, 50))\n",
        "    acq.set_ylim((0, np.max(utility) + 0.5))\n",
        "    acq.set_ylabel('Utility', fontdict={'size':20})\n",
        "    acq.set_xlabel('x', fontdict={'size':20})\n",
        "    plt.sca(acq)\n",
        "    plt.xticks(rotation='vertical')\n",
        "    \n",
        "    plt.legend(loc=2, bbox_to_anchor=(1.01, 1), borderaxespad=0.)\n",
        "    plt.legend(loc=2, bbox_to_anchor=(1.01, 1), borderaxespad=0.)\n",
        "\n",
        "    # Saving the image \n",
        "    plt.savefig(\"fig.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR-vQ29NYrXP",
        "colab_type": "code",
        "outputId": "f1ff59e8-9600-4b20-901b-256d15e5d38e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "# Sampling different points from the Gaussian based on different values of init_points, n_iter, and kappa\n",
        "optimizer.maximize(init_points=10, n_iter=10,kappa=10)\n",
        "plot_gp(optimizer, x, y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | batch_... | decay_... | dropou... | dropou... |    lr     |\n",
            "-------------------------------------------------------------------------------------\n",
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Test loss: 1.6039140939712524\n",
            "Test accuracy: 0.5359375\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.5359  \u001b[0m | \u001b[0m 227.2   \u001b[0m | \u001b[0m 0.3602  \u001b[0m | \u001b[0m 5.719e-0\u001b[0m | \u001b[0m 0.1512  \u001b[0m | \u001b[0m 0.01468 \u001b[0m |\n",
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Test loss: 2.2409221172332763\n",
            "Test accuracy: 0.20625\n",
            "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.2062  \u001b[0m | \u001b[0m 75.21   \u001b[0m | \u001b[0m 0.09313 \u001b[0m | \u001b[0m 0.1728  \u001b[0m | \u001b[0m 0.1984  \u001b[0m | \u001b[0m 0.05388 \u001b[0m |\n",
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Test loss: 2.1750051259994505\n",
            "Test accuracy: 0.2859375\n",
            "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.2859  \u001b[0m | \u001b[0m 228.2   \u001b[0m | \u001b[0m 0.3426  \u001b[0m | \u001b[0m 0.1022  \u001b[0m | \u001b[0m 0.4391  \u001b[0m | \u001b[0m 0.00274 \u001b[0m |\n",
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Test loss: 1.7480199098587037\n",
            "Test accuracy: 0.4484375\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.4484  \u001b[0m | \u001b[0m 345.8   \u001b[0m | \u001b[0m 0.2087  \u001b[0m | \u001b[0m 0.2793  \u001b[0m | \u001b[0m 0.07019 \u001b[0m | \u001b[0m 0.01981 \u001b[0m |\n",
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Test loss: 2.2399300575256347\n",
            "Test accuracy: 0.20625\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.2062  \u001b[0m | \u001b[0m 406.7   \u001b[0m | \u001b[0m 0.4841  \u001b[0m | \u001b[0m 0.1567  \u001b[0m | \u001b[0m 0.3462  \u001b[0m | \u001b[0m 0.08764 \u001b[0m |\n",
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Test loss: 2.2278658866882326\n",
            "Test accuracy: 0.20625\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.2062  \u001b[0m | \u001b[0m 450.7   \u001b[0m | \u001b[0m 0.04252 \u001b[0m | \u001b[0m 0.01953 \u001b[0m | \u001b[0m 0.08492 \u001b[0m | \u001b[0m 0.08781 \u001b[0m |\n",
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Test loss: 2.260592889785767\n",
            "Test accuracy: 0.20625\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.2062  \u001b[0m | \u001b[0m 78.03   \u001b[0m | \u001b[0m 0.2106  \u001b[0m | \u001b[0m 0.4789  \u001b[0m | \u001b[0m 0.2666  \u001b[0m | \u001b[0m 0.06919 \u001b[0m |\n",
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Test loss: 2.262274074554443\n",
            "Test accuracy: 0.20625\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.2062  \u001b[0m | \u001b[0m 179.7   \u001b[0m | \u001b[0m 0.3433  \u001b[0m | \u001b[0m 0.4173  \u001b[0m | \u001b[0m 0.009144\u001b[0m | \u001b[0m 0.07501 \u001b[0m |\n",
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Test loss: 1.4637362241744996\n",
            "Test accuracy: 0.5703125\n",
            "| \u001b[95m 9       \u001b[0m | \u001b[95m 0.5703  \u001b[0m | \u001b[95m 494.8   \u001b[0m | \u001b[95m 0.3741  \u001b[0m | \u001b[95m 0.1402  \u001b[0m | \u001b[95m 0.3946  \u001b[0m | \u001b[95m 0.01032 \u001b[0m |\n",
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Test loss: 2.023421323299408\n",
            "Test accuracy: 0.3234375\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.3234  \u001b[0m | \u001b[0m 241.6   \u001b[0m | \u001b[0m 0.4543  \u001b[0m | \u001b[0m 0.1468  \u001b[0m | \u001b[0m 0.1439  \u001b[0m | \u001b[0m 0.013   \u001b[0m |\n",
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Test loss: 2.2628979682922363\n",
            "Test accuracy: 0.1328125\n",
            "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.1328  \u001b[0m | \u001b[0m 209.7   \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Test loss: 2.22631413936615\n",
            "Test accuracy: 0.20625\n",
            "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.2062  \u001b[0m | \u001b[0m 264.8   \u001b[0m | \u001b[0m 0.0219  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Test loss: 2.2497959613800047\n",
            "Test accuracy: 0.20625\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.2062  \u001b[0m | \u001b[0m 474.7   \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Test loss: 2.2374417781829834\n",
            "Test accuracy: 0.20625\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.2062  \u001b[0m | \u001b[0m 322.3   \u001b[0m | \u001b[0m 0.1722  \u001b[0m | \u001b[0m 0.3999  \u001b[0m | \u001b[0m 0.4631  \u001b[0m | \u001b[0m 0.03006 \u001b[0m |\n",
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Test loss: 13.873112297058105\n",
            "Test accuracy: 0.18125\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.1813  \u001b[0m | \u001b[0m 369.0   \u001b[0m | \u001b[0m 0.02353 \u001b[0m | \u001b[0m 0.4758  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1e-06   \u001b[0m |\n",
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Test loss: 2.2726328134536744\n",
            "Test accuracy: 0.1328125\n",
            "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.1328  \u001b[0m | \u001b[0m 128.4   \u001b[0m | \u001b[0m 0.4113  \u001b[0m | \u001b[0m 0.002414\u001b[0m | \u001b[0m 0.4637  \u001b[0m | \u001b[0m 0.06889 \u001b[0m |\n",
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Test loss: 2.2559961318969726\n",
            "Test accuracy: 0.20625\n",
            "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.2062  \u001b[0m | \u001b[0m 32.0    \u001b[0m | \u001b[0m 0.1078  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.449   \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Test loss: 34.44027938842773\n",
            "Test accuracy: 0.1140625\n",
            "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.1141  \u001b[0m | \u001b[0m 293.6   \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 1e-06   \u001b[0m |\n",
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Test loss: 2.2462942838668822\n",
            "Test accuracy: 0.20625\n",
            "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.2062  \u001b[0m | \u001b[0m 154.6   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
            "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
            "Test loss: 12.96047601699829\n",
            "Test accuracy: 0.1125\n",
            "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.1125  \u001b[0m | \u001b[0m 103.1   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1e-06   \u001b[0m |\n",
            "=====================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_QpG74xc_V7",
        "colab_type": "text"
      },
      "source": [
        "# Plotting reference:\n",
        "https://github.com/fmfn/BayesianOptimization/blob/master/examples/visualization.ipynb"
      ]
    }
  ]
}